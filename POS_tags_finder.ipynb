{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk \n",
    "from nltk.corpus import state_union                       # for training our tokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer          # tokenizer\n",
    "nltk.download('state_union')                              # text for training \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "train_text = state_union.raw('2006-GWBush.txt')\n",
    "sample_text = \"Ram is a good boy\"                        # our text to be given \n",
    "\n",
    "custom_tokenizer = PunktSentenceTokenizer(train_text)    # tokenizer getting trained\n",
    "tokenized = custom_tokenizer.tokenize(sample_text)       # tokenizing our text\n",
    "\n",
    "\n",
    "def pos():\n",
    "  try:\n",
    "    for i in tokenized:\n",
    "      words = nltk.word_tokenize(i)\n",
    "      pos_tags = nltk.pos_tag(words)\n",
    "      print(pos_tags)\n",
    "  \n",
    "  except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "\n",
    "pos()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To find which pos means what \n",
    "\n",
    "nltk.download('tagsets')\n",
    "\n",
    "nltk.help.upenn_tagset('NNP')\n",
    "nltk.help.upenn_tagset('VBZ')\n",
    "nltk.help.upenn_tagset('DT')\n",
    "nltk.help.upenn_tagset('JJ')\n",
    "nltk.help.upenn_tagset('NN')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Syntax tree\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text1 = 'Ram is a good boy'\n",
    "\n",
    "tokens = nltk.pos_tag(word_tokenize(text1))\n",
    "tokens\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grammer_np= r'NP: {<DT>?<JJ>*<NN>}'\n",
    "\n",
    "chunk_parser = nltk.RegexpParser(grammer_np)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "chunk_result = chunk_parser.parse(tokens)\n",
    "chunk_result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tree('S', [('Ram', 'NNP'), ('is', 'VBZ'), Tree('NP', [('a', 'DT'), ('good', 'JJ'), ('boy', 'NN')])])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk \n",
    "# from nltk.corpus import state_union                       # for training our tokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer          # tokenizer\n",
    "# nltk.download('state_union')                              # text for training \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "# train_text = state_union.raw('2006-GWBUsh.txt')\n",
    "sample_text = \"Ram is a good boy\"                        # our text to be given \n",
    "\n",
    "custom_tokenizer = PunktSentenceTokenizer()    # tokenizer getting trained\n",
    "tokenized = custom_tokenizer.tokenize(sample_text)       # tokenizing our text\n",
    "\n",
    "\n",
    "def pos():\n",
    "  try:\n",
    "    for i in tokenized:\n",
    "      words = nltk.word_tokenize(i)\n",
    "      pos_tags = nltk.pos_tag(words)\n",
    "      print(pos_tags)\n",
    "  \n",
    "  except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "\n",
    "pos()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('virtual_environment_midsemAssignment': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "4b2ac9b6839f9404340648d7ccfa655a8d04ed4b63b58041686ac710e5c52c91"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}